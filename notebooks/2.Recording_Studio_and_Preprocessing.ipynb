{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recording Studio\n",
    "\n",
    "This notebook is intended to record, preprocess and save the audios that will be later used by pyramidman assistant. It will make use of the speech recognizing as well for practical purposes, but theses will not be explained in this notebook, but rather in the third one.\n",
    "\n",
    "This notebook focuses on making a proper listener in another thread that writes the audio data into a Queue that is later consumed by the main thread and in having a simple Recording Studio for making the audios for pyramidman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/montoya/anaconda3/envs/python36/lib/python3.7/site-packages/tqdm/autonotebook.py:17: TqdmExperimentalWarning:\n",
      "\n",
      "Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from pyramidman.audio_parameters import AudioParameters\n",
    "from pyramidman.basic_audio_IO import play_audio, record_audio\n",
    "from pyramidman.audio_utils import get_available_microphones, get_sysdefault_microphone_index, get_all_devices_str\n",
    "from pyramidman.queue_utils import record_with_queue\n",
    "from pyramidman.unwrapper import unwrap\n",
    "from pyramidman.speech_recognizing import recognize_speech_from_mic\n",
    "from pyramidman.hieroglyph import plot_timeseries_range_slider, create_tabs, plot_spectrogram\n",
    "from pyramidman.hieroglyph import add_word_annotations\n",
    "\n",
    "from pyramidman.Ihy import get_audio_menu_wav_file\n",
    "from pyramidman.signal_processing import get_spectrogram\n",
    "\n",
    "from pyramidman.queue_utils import put_audio_data_in_queue_callback_closure, listen_in_a_thread\n",
    "from pyramidman.audio_utils import calibrate_microphone\n",
    "\n",
    "import speech_recognition as sr\n",
    "from pyramidman.deepspeech_tools import transcribe, DeepSpeechArgs\n",
    "\n",
    "import plotly\n",
    "import time\n",
    "\n",
    "%matplotlib qt\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import plotly.graph_objs as go\n",
    "from IPython.display import display\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal\n",
    "from scipy.io import wavfile\n",
    "import ipywidgets as widgets\n",
    "\n",
    "from queue import Queue\n",
    "import noisereduce as nr\n",
    "import librosa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instantiate and calibrate microphone\n",
    "\n",
    "Ideally, we would like a background process in a thread that whenever a sentence is finished, it is translated and plotted. This is the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_params = AudioParameters()\n",
    "audio_params.set_sysdefault_microphone_index()\n",
    "audio_params.set_default_input_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_params.input_device_index = 6\n",
    "audio_params.sample_rate = 48000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calibrating microphone for 3 seconds.\n",
      "Calibrated\n"
     ]
    }
   ],
   "source": [
    "mic = audio_params.get_microphone()\n",
    "r = sr.Recognizer()\n",
    "\n",
    "calibrate_microphone(mic, r, duration = 3, dynamic_energy_threshold= False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Microphone>\tobject has children:\n",
      "    <module>\tpyaudio_module\n",
      "    <int>\tdevice_index:\t6\n",
      "    <int>\tformat:\t8\n",
      "    <int>\tSAMPLE_WIDTH:\t2\n",
      "    <int>\tSAMPLE_RATE:\t48000\n",
      "    <int>\tCHUNK:\t1024\n",
      "    <PyAudio>\taudio\n",
      "    <NoneType>\tstream:\tNone\n",
      "\n",
      "  <PyAudio>\taudio has children:\n",
      "\n",
      "  <module>\tpyaudio_module has children:\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "unwrap(mic, max_level = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Minimize noise expetiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording\n",
      "Finished recording\n"
     ]
    }
   ],
   "source": [
    "file_to_record = \"../audios/temp/recording.wav\"\n",
    "record_audio(audio_params, seconds = 5, filename = file_to_record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "play_audio(audio_params, file_to_record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# load data\n",
    "rate, data = wavfile.read(file_to_record)\n",
    "data = data.astype(float)\n",
    "# select section of data that is noise\n",
    "initial_noise_duration = 1\n",
    "noisy_part = data[:int(audio_params.sample_rate/initial_noise_duration)]\n",
    "\n",
    "# perform noise reduction\n",
    "reduced_noise = nr.reduce_noise(audio_clip=data, noise_clip=noisy_part, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_noise = reduced_noise.astype(np.int16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_to_record_reduced = \"../audios/temp/recording_reduced.wav\"\n",
    "wavfile.write(file_to_record_reduced, audio_params.sample_rate, reduced_noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "564ec49277cd4a3686bab741ae54199d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tab(children=(FigureWidget({\n",
       "    'data': [{'line': {'color': 'deepskyblue'},\n",
       "              'name': 'AAPL High'…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tabs = get_audio_menu_wav_file(file_to_record)\n",
    "display(tabs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d84ef4ef0a6e437b8b410270416b62ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tab(children=(FigureWidget({\n",
       "    'data': [{'line': {'color': 'deepskyblue'},\n",
       "              'name': 'AAPL High'…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tabs = get_audio_menu_wav_file(file_to_record_reduced)\n",
    "display(tabs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(239616,) (239616,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([     0, 239616])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load some audio\n",
    "# Trim the beginning and ending silence\n",
    "\n",
    "yt, index = librosa.effects.trim(reduced_noise.astype(float),top_db=20, ref=np.max, frame_length=512*4, hop_length=256*4)\n",
    "print(yt.shape, reduced_noise.shape)\n",
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_to_record_reduced_cut = \"../audios/temp/recording_reduced_cut.wav\"\n",
    "wavfile.write(file_to_record_reduced_cut, audio_params.sample_rate, yt.astype(np.int16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8c70c8d5fe84278abc50625ca5b6297",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tab(children=(FigureWidget({\n",
       "    'data': [{'line': {'color': 'deepskyblue'},\n",
       "              'name': 'AAPL High'…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tabs = get_audio_menu_wav_file(file_to_record_reduced_cut)\n",
    "display(tabs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transcribe to know which approach is better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "play_audio(audio_params, file_to_record)\n",
    "play_audio(audio_params, file_to_record_reduced)\n",
    "play_audio(audio_params, file_to_record_reduced_cut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = DeepSpeechArgs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcribe(args, file_to_record)[\"sentence\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcribe(args, file_to_record_reduced)[\"sentence\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcribe(args, file_to_record_reduced_cut)[\"sentence\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Listen in background\n",
    "\n",
    "Create a thread that records in the background and puts the sentences read into queue that has as input the "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning the parameters of the listening."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.non_speaking_duration = 0.2\n",
    "r.pause_threshold = 1.2\n",
    "r.energy_threshold = 2500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-11:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/montoya/anaconda3/envs/python36/lib/python3.7/threading.py\", line 926, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/montoya/anaconda3/envs/python36/lib/python3.7/threading.py\", line 870, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/montoya/Desktop/VScode/pyramidman/pyramidman/queue_utils.py\", line 83, in threaded_listen\n",
      "    with source as s:\n",
      "  File \"/home/montoya/anaconda3/envs/python36/lib/python3.7/site-packages/speech_recognition/__init__.py\", line 134, in __enter__\n",
      "    assert self.stream is None, \"This audio source is already inside a context manager\"\n",
      "AssertionError: This audio source is already inside a context manager\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Stop listening will stop the thread\n",
    "q = Queue()\n",
    "put_audio_data_in_queue_callback = put_audio_data_in_queue_callback_closure(r, mic, q)\n",
    "stop_listening = listen_in_a_thread(r, mic, put_audio_data_in_queue_callback, phrase_time_limit = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Consume the audios put in the queue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-98590b95708f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mfilename_mic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf'../audios/temp/{i}.wav'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0maudio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Saving... \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python36/lib/python3.7/queue.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    168\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m                 \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_qsize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_empty\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"'timeout' must be a non-negative number\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python36/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "while(True):\n",
    "    \n",
    "    filename_mic = f'../audios/temp/{i}.wav'\n",
    "    audio = q.get()\n",
    "    \n",
    "    print(\"Saving... \", end = \"\")\n",
    "    with open(filename_mic, \"wb\") as f:\n",
    "        f.write(audio.get_wav_data())\n",
    "\n",
    "    \"\"\"     \n",
    "    if i == 0:\n",
    "        tabs = get_audio_menu_wav_file(filename_mic)\n",
    "        display(tabs)\n",
    "    else:\n",
    "        tabs_next = get_audio_menu_wav_file(filename_mic)\n",
    "        tabs.children = tabs_next.children\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"Transcribing...: \", end=\"\")\n",
    "    args = DeepSpeechArgs()\n",
    "    metadata = transcribe(args, filename_mic)\n",
    "\n",
    "    print(metadata[\"sentence\"])\n",
    "    # add_word_annotations(tabs.children[0],metadata[\"words\"])\n",
    "    \n",
    "    if \"pyramid man\" in metadata[\"sentence\"]:\n",
    "        print(\"Activated broh\")\n",
    "        play_audio(audio_params, filename_mic)\n",
    "    \n",
    "    i+=1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stop listening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calling this function requests that the background listener stop listening\n",
    "stop_listening(wait_for_stop=False)\n",
    "q.empty()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recording studio.\n",
    "\n",
    "We have created a simple plotly UI to record and save the audios for the pyramidman assistant. This can be reused in the future for extension of capabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "mic = audio_params.get_microphone()\n",
    "r = sr.Recognizer()\n",
    "\n",
    "figure_box = widgets.Box([go.FigureWidget()])\n",
    "\n",
    "def record_button_callback(button):\n",
    "    if button.description == \"Start\":\n",
    "        filename_mic = '../audios/temp/hello_world.wav'\n",
    "\n",
    "        with mic as source:\n",
    "            # audio = r.record(source,duration = 2)\n",
    "            audio = r.listen(source)\n",
    "            \n",
    "        with open(filename_mic, \"wb\") as f:\n",
    "            f.write(audio.get_wav_data())\n",
    "        \n",
    "        figure_box.children = [get_audio_menu_wav_file(filename_mic)]\n",
    "        \n",
    "button_record = widgets.Button(\n",
    "    value=False,\n",
    "    description='Start',\n",
    "    button_style='', # 'success', 'info', 'warning', 'danger' or ''\n",
    "    icon='check'\n",
    ")\n",
    "\n",
    "button_record.on_click(record_button_callback)\n",
    "\n",
    "                      \n",
    "recorder_box = widgets.VBox([button_record, figure_box])\n",
    "display(recorder_box)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
