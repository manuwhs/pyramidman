{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recording Studio\n",
    "\n",
    "This notebook is intended to record, preprocess and save the audios that will be later used by pyramidman assistant. It will make use of the speech recognizing as well for practical purposes, but theses will not be explained in this notebook, but rather in the third one.\n",
    "\n",
    "This notebook focuses on making a proper listener in another thread that writes the audio data into a Queue that is later consumed by the main thread and in having a simple Recording Studio for making the audios for pyramidman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from pyramidman.audio_parameters import AudioParameters\n",
    "from pyramidman.basic_audio_IO import play_audio, record_audio\n",
    "from pyramidman.audio_utils import get_available_microphones, get_sysdefault_microphone_index, get_all_devices_str\n",
    "from pyramidman.queue_utils import record_with_queue\n",
    "from pyramidman.unwrapper import unwrap\n",
    "from pyramidman.speech_recognizing import recognize_speech_from_mic\n",
    "from pyramidman.hieroglyph import plot_timeseries_range_slider, create_tabs, plot_spectrogram\n",
    "from pyramidman.hieroglyph import add_word_annotations\n",
    "\n",
    "from pyramidman.Ihy import get_audio_menu_wav_file\n",
    "from pyramidman.signal_processing import get_spectrogram\n",
    "\n",
    "from pyramidman.queue_utils import put_audio_data_in_queue_callback_closure, listen_in_a_thread\n",
    "from pyramidman.audio_utils import calibrate_microphone\n",
    "\n",
    "import speech_recognition as sr\n",
    "from pyramidman.deepspeech_tools import transcribe, DeepSpeechArgs\n",
    "\n",
    "import plotly\n",
    "import time\n",
    "\n",
    "%matplotlib qt\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import plotly.graph_objs as go\n",
    "from IPython.display import display\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal\n",
    "from scipy.io import wavfile\n",
    "import ipywidgets as widgets\n",
    "\n",
    "from queue import Queue\n",
    "import noisereduce as nr\n",
    "import librosa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instantiate and calibrate microphone\n",
    "\n",
    "Ideally, we would like a background process in a thread that whenever a sentence is finished, it is translated and plotted. This is the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_params = AudioParameters()\n",
    "audio_params.set_sysdefault_microphone_index()\n",
    "audio_params.set_default_input_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_params.input_device_index = 6\n",
    "audio_params.sample_rate = 48000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calibrating microphone for 5 seconds.\n",
      "Calibrated\n"
     ]
    }
   ],
   "source": [
    "mic = audio_params.get_microphone()\n",
    "r = sr.Recognizer()\n",
    "\n",
    "calibrate_microphone(mic, r, duration = 3, dynamic_energy_threshold= True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.non_speaking_duration\n",
    "r.pause_threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Minimize noise expetiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording\n",
      "Finished recording\n"
     ]
    }
   ],
   "source": [
    "file_to_record = \"../audios/temp/recording.wav\"\n",
    "record_audio(audio_params, seconds = 5, filename = file_to_record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "play_audio(audio_params, file_to_record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# load data\n",
    "rate, data = wavfile.read(file_to_record)\n",
    "data = data.astype(float)\n",
    "# select section of data that is noise\n",
    "initial_noise_duration = 1\n",
    "noisy_part = data[:int(audio_params.sample_rate/initial_noise_duration)]\n",
    "\n",
    "# perform noise reduction\n",
    "reduced_noise = nr.reduce_noise(audio_clip=data, noise_clip=noisy_part, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_noise = reduced_noise.astype(np.int16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_to_record_reduced = \"../audios/temp/recording_reduced.wav\"\n",
    "wavfile.write(file_to_record_reduced, audio_params.sample_rate, reduced_noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c81325418f3e4000af0b57616c979544",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tab(children=(FigureWidget({\n",
       "    'data': [{'line': {'color': 'deepskyblue'},\n",
       "              'name': 'AAPL High'…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tabs = get_audio_menu_wav_file(file_to_record)\n",
    "display(tabs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f3909fc72784cc599fef543197b8eb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tab(children=(FigureWidget({\n",
       "    'data': [{'line': {'color': 'deepskyblue'},\n",
       "              'name': 'AAPL High'…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tabs = get_audio_menu_wav_file(file_to_record_reduced)\n",
    "display(tabs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(98304,) (239616,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 95232, 193536])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load some audio\n",
    "# Trim the beginning and ending silence\n",
    "\n",
    "yt, index = librosa.effects.trim(reduced_noise.astype(float),top_db=20, ref=np.max, frame_length=512*4, hop_length=256*4)\n",
    "print(yt.shape, reduced_noise.shape)\n",
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_to_record_reduced_cut = \"../audios/temp/recording_reduced_cut.wav\"\n",
    "wavfile.write(file_to_record_reduced_cut, audio_params.sample_rate, yt.astype(np.int16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0b4bdd48f134e2097c963b84e73542f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tab(children=(FigureWidget({\n",
       "    'data': [{'line': {'color': 'deepskyblue'},\n",
       "              'name': 'AAPL High'…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tabs = get_audio_menu_wav_file(file_to_record_reduced_cut)\n",
    "display(tabs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transcribe to know which approach is better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "play_audio(audio_params, file_to_record)\n",
    "play_audio(audio_params, file_to_record_reduced)\n",
    "play_audio(audio_params, file_to_record_reduced_cut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = DeepSpeechArgs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'this is the best day of my life man'"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcribe(args, file_to_record)[\"sentence\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'this is the best the of my life man'"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcribe(args, file_to_record_reduced)[\"sentence\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the best they have my life man'"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcribe(args, file_to_record_reduced_cut)[\"sentence\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Listen in background\n",
    "\n",
    "Create a thread that records in the background and puts the sentences read into queue that has as input the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Stop listening will stop the thread\n",
    "q = Queue()\n",
    "put_audio_data_in_queue_callback = put_audio_data_in_queue_callback_closure(r, mic, q)\n",
    "stop_listening = listen_in_a_thread(r, mic, put_audio_data_in_queue_callback, phrase_time_limit = 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Consume the audios put in the queue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving... Transcribing...: is this finally up to me\n",
      "Saving... Transcribing...: a\n",
      "Saving... Transcribing...: i\n",
      "Saving... Transcribing...: maybe it is but this is very faulty and life is short\n",
      "Saving... Transcribing...: and is actually were cane of a kano\n",
      "Saving... Transcribing...: he had to shorten the sentences to be honest why this it not and\n",
      "Saving... Transcribing...: i\n",
      "Saving... Transcribing...: i\n",
      "Saving... Transcribing...: i\n",
      "Saving... Transcribing...: i\n",
      "Saving... Transcribing...: i\n",
      "Saving... Transcribing...: yes have you told some fellers is\n",
      "Saving... Transcribing...: pyramid men attack pyramid man come by rome man do it pyramid men you can\n",
      "Activated broh\n",
      "Saving... Transcribing...: hiram men attack orinoco i roman long to it i remember you can't\n",
      "Saving... Transcribing...: i\n",
      "Saving... Transcribing...: i have to laud this in a more elegant way as you but we will get there\n",
      "Saving... Transcribing...: i\n",
      "Saving... Transcribing...: i\n",
      "Saving... Transcribing...: i\n",
      "Saving... Transcribing...: i\n",
      "Saving... Transcribing...: i\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-72-98590b95708f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mfilename_mic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf'../audios/temp/{i}.wav'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0maudio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Saving... \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python36/lib/python3.7/queue.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    168\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m                 \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_qsize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_empty\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"'timeout' must be a non-negative number\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python36/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "while(True):\n",
    "    \n",
    "    filename_mic = f'../audios/temp/{i}.wav'\n",
    "    audio = q.get()\n",
    "    \n",
    "    print(\"Saving... \", end = \"\")\n",
    "    with open(filename_mic, \"wb\") as f:\n",
    "        f.write(audio.get_wav_data())\n",
    "\n",
    "    \"\"\"     \n",
    "    if i == 0:\n",
    "        tabs = get_audio_menu_wav_file(filename_mic)\n",
    "        display(tabs)\n",
    "    else:\n",
    "        tabs_next = get_audio_menu_wav_file(filename_mic)\n",
    "        tabs.children = tabs_next.children\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"Transcribing...: \", end=\"\")\n",
    "    args = DeepSpeechArgs()\n",
    "    metadata = transcribe(args, filename_mic)\n",
    "\n",
    "    print(metadata[\"sentence\"])\n",
    "    # add_word_annotations(tabs.children[0],metadata[\"words\"])\n",
    "    \n",
    "    if \"pyramid man\" in metadata[\"sentence\"]:\n",
    "        print(\"Activated broh\")\n",
    "        play_audio(audio_params, filename_mic)\n",
    "    \n",
    "    i+=1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stop listening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calling this function requests that the background listener stop listening\n",
    "stop_listening(wait_for_stop=False)\n",
    "q.empty()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recording studio.\n",
    "\n",
    "We have created a simple plotly UI to record and save the audios for the pyramidman assistant. This can be reused in the future for extension of capabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "586be8c964974bb982d76aa9be3bf517",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Button(description='Start', icon='check', style=ButtonStyle()), Box(children=(FigureWidget({\n",
       "  …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mic = audio_params.get_microphone()\n",
    "r = sr.Recognizer()\n",
    "\n",
    "figure_box = widgets.Box([go.FigureWidget()])\n",
    "\n",
    "def record_button_callback(button):\n",
    "    if button.description == \"Start\":\n",
    "        filename_mic = '../audios/temp/hello_world.wav'\n",
    "\n",
    "        with mic as source:\n",
    "            # audio = r.record(source,duration = 2)\n",
    "            audio = r.listen(source)\n",
    "            \n",
    "        with open(filename_mic, \"wb\") as f:\n",
    "            f.write(audio.get_wav_data())\n",
    "        \n",
    "        figure_box.children = [get_audio_menu_wav_file(filename_mic)]\n",
    "        \n",
    "button_record = widgets.Button(\n",
    "    value=False,\n",
    "    description='Start',\n",
    "    button_style='', # 'success', 'info', 'warning', 'danger' or ''\n",
    "    icon='check'\n",
    ")\n",
    "\n",
    "button_record.on_click(record_button_callback)\n",
    "\n",
    "                      \n",
    "recorder_box = widgets.VBox([button_record, figure_box])\n",
    "display(recorder_box)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
