{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Audio Basics\n",
    "\n",
    "A walkthough the different functions in pyramidman that handle the recording, playing and processing of audio. It is mainly for didactic and testing purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from pyramidman.audio_parameters import AudioParameters\n",
    "from pyramidman.basic_audio_IO import play_audio, record_audio\n",
    "from pyramidman.audio_utils import get_available_microphones, get_sysdefault_microphone_index, get_all_devices_str\n",
    "from pyramidman.queue_utils import record_with_queue\n",
    "from pyramidman.unwrapper import unwrap\n",
    "\n",
    "from pyramidman.Ihy import get_audio_menu_wav_file\n",
    "\n",
    "from pyramidman.audio_utils import calibrate_microphone\n",
    "\n",
    "\n",
    "import speech_recognition as sr\n",
    "import numpy as np\n",
    "from scipy import signal\n",
    "from scipy.io import wavfile\n",
    "\n",
    "import plotly.graph_objs as go\n",
    "from IPython.display import display\n",
    "import ipywidgets as widgets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instance of the class AudioParameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<AudioParameters>\tobject has children:\n",
      "    <int>\tchunk:\t1024\n",
      "    <int>\tsample_format:\t8\n",
      "    <NoneType>\tsubtype:\tNone\n",
      "    <int>\tchannels:\t1\n",
      "    <int>\tsample_rate:\t48000\n",
      "    <int>\tinput_device_index:\t0\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "audio_params = AudioParameters()\n",
    "unwrap(audio_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'HDA Intel PCH: ALC295 Analog (hw:0,0)',\n",
       " 'hostapi': 0,\n",
       " 'max_input_channels': 2,\n",
       " 'max_output_channels': 2,\n",
       " 'default_low_input_latency': 0.005804988662131519,\n",
       " 'default_low_output_latency': 0.005804988662131519,\n",
       " 'default_high_input_latency': 0.034829931972789115,\n",
       " 'default_high_output_latency': 0.034829931972789115,\n",
       " 'default_samplerate': 44100.0}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio_params.get_input_device_info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Information of avilable devices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   0 HDA Intel PCH: ALC295 Analog (hw:0,0), ALSA (2 in, 2 out)\n",
       "   1 HDA Intel PCH: HDMI 0 (hw:0,3), ALSA (0 in, 8 out)\n",
       "   2 HDA Intel PCH: HDMI 1 (hw:0,7), ALSA (0 in, 8 out)\n",
       "   3 HDA Intel PCH: HDMI 2 (hw:0,8), ALSA (0 in, 8 out)\n",
       "   4 HDA Intel PCH: HDMI 3 (hw:0,9), ALSA (0 in, 8 out)\n",
       "   5 HDA Intel PCH: HDMI 4 (hw:0,10), ALSA (0 in, 8 out)\n",
       "   6 sysdefault, ALSA (128 in, 128 out)\n",
       "   7 front, ALSA (0 in, 2 out)\n",
       "   8 surround40, ALSA (0 in, 2 out)\n",
       "   9 surround51, ALSA (0 in, 2 out)\n",
       "  10 surround71, ALSA (0 in, 2 out)\n",
       "  11 hdmi, ALSA (0 in, 8 out)\n",
       "  12 pulse, ALSA (32 in, 32 out)\n",
       "  13 dmix, ALSA (0 in, 2 out)\n",
       "* 14 default, ALSA (32 in, 32 out)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_all_devices_str()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0': 'HDA Intel PCH: ALC295 Analog (hw:0,0)',\n",
       " '6': 'sysdefault',\n",
       " '12': 'pulse',\n",
       " '14': 'default'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "devices_dict = get_available_microphones()\n",
    "devices_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Play audio\n",
    "\n",
    "We pass it a AudioParameters instance, from it, it is going to get chunk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_to_play = \"../audios/standard/english.wav\"\n",
    "play_audio(audio_params, filename = file_to_play )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recording audio\n",
    "\n",
    "First we should select a proper mycrophone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<AudioParameters>\tobject has children:\n",
      "    <int>\tchunk:\t1024\n",
      "    <int>\tsample_format:\t8\n",
      "    <NoneType>\tsubtype:\tNone\n",
      "    <int>\tchannels:\t1\n",
      "    <int>\tsample_rate:\t48000\n",
      "    <int>\tinput_device_index:\t6\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "audio_params.set_sysdefault_microphone_index()\n",
    "audio_params.set_default_input_parameters()\n",
    "unwrap(audio_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Call the recording function with the correct parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording\n",
      "Finished recording\n"
     ]
    }
   ],
   "source": [
    "file_to_record = \"../audios/temp/recording.wav\"\n",
    "record_audio(audio_params, seconds = 3, filename = file_to_record)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Play the recorded audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "play_audio(audio_params,  filename = file_to_record)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Record using queues\n",
    "\n",
    "It seems better, with way less in between cuts that are probably because there is less delay due to processing of the chucks. But still as time grows, this shit takes too much time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Recording finished: \n"
     ]
    }
   ],
   "source": [
    "filename_w = \"../audios/temp/caec2.wav\"\n",
    "record_with_queue(audio_params, filename_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "play_audio(audio_params, filename_w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using a Microphone\n",
    "\n",
    "The speech_recognition library has a Microphone class that is helpful at recording data. We can get one instance directly from the AudioParameters class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "mic = audio_params.get_microphone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mic.device_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['HDA Intel PCH: ALC295 Analog (hw:0,0)',\n",
       " 'HDA Intel PCH: HDMI 0 (hw:0,3)',\n",
       " 'HDA Intel PCH: HDMI 1 (hw:0,7)',\n",
       " 'HDA Intel PCH: HDMI 2 (hw:0,8)',\n",
       " 'HDA Intel PCH: HDMI 3 (hw:0,9)',\n",
       " 'HDA Intel PCH: HDMI 4 (hw:0,10)',\n",
       " 'sysdefault',\n",
       " 'front',\n",
       " 'surround40',\n",
       " 'surround51',\n",
       " 'surround71',\n",
       " 'hdmi',\n",
       " 'pulse',\n",
       " 'dmix',\n",
       " 'default']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mic.list_microphone_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use this instance to together with the recognizer of the library in order to capture text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<speech_recognition.AudioData at 0x7f13a9416a50>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = sr.Recognizer()\n",
    "with mic as source:                # use the default microphone as the audio source\n",
    "    audio = r.record(source, duration = 3)                   # listen for the first phrase and extract it into audio data\n",
    "\n",
    "audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<AudioData>\tobject has children:\n",
      "    <bytes>\tframe_data\n",
      "    <int>\tsample_rate:\t48000\n",
      "    <int>\tsample_width:\t2\n",
      "\n",
      "  <bytes>\tframe_data has children:\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "unwrap(audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_mic = '../audios/temp/hello_world.wav'\n",
    "\n",
    "with mic as source:\n",
    "    audio = r.record(source,duration = 5)\n",
    "\n",
    "with open(filename_mic, \"wb\") as f:\n",
    "    f.write(audio.get_wav_data())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "play_audio(audio_params, filename_mic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert audio to numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bytes"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio_raw_data = audio.frame_data\n",
    "audio_raw_data = audio.get_raw_data()\n",
    "type(audio_raw_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1502, -1436, -1600, ..., -4596, -4376, -4170], dtype=int16)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio_array = np.frombuffer(audio.frame_data, np.int16)\n",
    "audio_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting of the audiowave."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7b5b47e5ba8418286b998b681f3f9b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tab(children=(FigureWidget({\n",
       "    'data': [{'line': {'color': 'deepskyblue'},\n",
       "              'name': 'AAPL High'â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tabs = get_audio_menu_wav_file(filename_mic)\n",
    "display(tabs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Own listener implementation\n",
    "\n",
    "Since the listener from the speech_recognition library was not good enough, we have implemented another one.\n",
    "\n",
    "The main changes are:\n",
    "- Refactoring of code.\n",
    "- Removing the snowboy option\n",
    "- Adding timestamp of the returned data.\n",
    "- Adding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyramidman.listener import listen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Maximum number of seconds of non-speaking seconds before and after the audio\n",
    "r.non_speaking_duration\n",
    "\n",
    "# Number of non-speaking seconds to be considered end of sentence.\n",
    "r.pause_threshold\n",
    "\n",
    "# Minimum number of seconds of a sentence.\n",
    "r.phrase_threshold\n",
    "\n",
    "# The amount of energy in \n",
    "r.energy_threshold\n",
    "\n",
    "# Number of bytes in the \n",
    "mic.SAMPLE_WIDTH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "keyword can't be an expression (<ipython-input-29-2126205d9c6b>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-29-2126205d9c6b>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    audio = listen(r, source. timeout = 1, phrase_time_limit=5)\u001b[0m\n\u001b[0m                     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m keyword can't be an expression\n"
     ]
    }
   ],
   "source": [
    "with mic as source:\n",
    "    audio = listen(r, source, timeout = 1, phrase_time_limit=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
