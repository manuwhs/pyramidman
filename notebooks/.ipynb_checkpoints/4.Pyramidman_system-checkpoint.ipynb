{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fee pyramidman.Seshat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/montoya/anaconda3/envs/python36/lib/python3.7/site-packages/tqdm/autonotebook.py:17: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  \" (e.g. in jupyter console)\", TqdmExperimentalWarning)\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from pyramidman.speech_commands import SpeechCommandsHandler\n",
    "from pyramidman.Seshat import Transcriber\n",
    "from pyramidman.unwrapper import unwrap\n",
    "from pyramidman.meeting_facilitator import MeetingFacilitator\n",
    "from pyramidman.email import EmailConfig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Meeting facilitator\n",
    "\n",
    "A meeting facilitator is basically a state machine that has a Transcriber, explained in the previous notebook, and a Command handler, with some visual extra steps. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "meeting_facilitator = MeetingFacilitator(\"my_meeting\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<MeetingFacilitator>\tobject has children:\n",
      "    <str>\tmeeting_name:\tmy_meeting\n",
      "    <str>\tdate:\t2020-01-04 22:47:36.179749\n",
      "    <NoneType>\tattendants:\tNone\n",
      "    <str>\taudios_folder:\t../meetings/my_meeting/audios/\n",
      "    <str>\treports_folder:\t..meetings/my_meeting/reports/\n",
      "    <NoneType>\ttranscriber:\tNone\n",
      "    <NoneType>\tspeech_command_handler:\tNone\n",
      "    <NoneType>\t_stop_command_handler_in_background_func:\tNone\n",
      "    <bool>\t_is_handling_commands:\tFalse\n",
      "    <list>\t_trainscriptions_list\n",
      "\n",
      "  <list>\t_trainscriptions_list has children:\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "unwrap(meeting_facilitator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calibrating microphone for 1 seconds.\n",
      "Calibrated energy threshold:  2193.303922801633\n"
     ]
    }
   ],
   "source": [
    "meeting_facilitator.set_automatic_default_transcriber()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "email_config = EmailConfig()\n",
    "meeting_facilitator.set_email_config(email_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "meeting_facilitator.set_default_speech_command_handler()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing  the my play music\n",
      "keyword detected\n",
      "playing\n"
     ]
    }
   ],
   "source": [
    "speech_command_handler = meeting_facilitator.speech_command_handler\n",
    "\n",
    "speech_command_handler.process(\"the my play music\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start and Stop "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading model from file ../models/deepspeech/deepspeech-0.6.0-models/output_graph.pbmm\n",
      "Loaded model in 0.0328s.\n",
      "Loading language model from files ../models/deepspeech/deepspeech-0.6.0-models/lm.binary ../models/deepspeech/deepspeech-0.6.0-models/trie\n",
      "Loaded language model in 0.000326s.\n",
      "Warning: original sample rate (48000) is different than 16000hz. Resampling might produce erratic speech recognition.\n",
      "Running inference.\n",
      "Inference took 2.059s for 13.056s audio file.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing  well now it works\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading model from file ../models/deepspeech/deepspeech-0.6.0-models/output_graph.pbmm\n",
      "Loaded model in 0.00588s.\n",
      "Loading language model from files ../models/deepspeech/deepspeech-0.6.0-models/lm.binary ../models/deepspeech/deepspeech-0.6.0-models/trie\n",
      "Loaded language model in 0.000347s.\n",
      "Warning: original sample rate (48000) is different than 16000hz. Resampling might produce erratic speech recognition.\n",
      "Running inference.\n",
      "Inference took 2.544s for 16.896s audio file.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing  my play music\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading model from file ../models/deepspeech/deepspeech-0.6.0-models/output_graph.pbmm\n",
      "Loaded model in 0.0236s.\n",
      "Loading language model from files ../models/deepspeech/deepspeech-0.6.0-models/lm.binary ../models/deepspeech/deepspeech-0.6.0-models/trie\n",
      "Loaded language model in 0.000798s.\n",
      "Warning: original sample rate (48000) is different than 16000hz. Resampling might produce erratic speech recognition.\n",
      "Running inference.\n",
      "Inference took 1.809s for 11.264s audio file.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing  a gifford given this\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading model from file ../models/deepspeech/deepspeech-0.6.0-models/output_graph.pbmm\n",
      "Loaded model in 0.018s.\n",
      "Loading language model from files ../models/deepspeech/deepspeech-0.6.0-models/lm.binary ../models/deepspeech/deepspeech-0.6.0-models/trie\n",
      "Loaded language model in 0.00086s.\n",
      "Warning: original sample rate (48000) is different than 16000hz. Resampling might produce erratic speech recognition.\n",
      "Running inference.\n",
      "Inference took 2.405s for 15.104s audio file.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing  the mine yet there may play music\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading model from file ../models/deepspeech/deepspeech-0.6.0-models/output_graph.pbmm\n",
      "Loaded model in 0.0222s.\n",
      "Loading language model from files ../models/deepspeech/deepspeech-0.6.0-models/lm.binary ../models/deepspeech/deepspeech-0.6.0-models/trie\n",
      "Loaded language model in 0.000789s.\n",
      "Warning: original sample rate (48000) is different than 16000hz. Resampling might produce erratic speech recognition.\n",
      "Running inference.\n",
      "Inference took 0.710s for 4.096s audio file.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing  i\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading model from file ../models/deepspeech/deepspeech-0.6.0-models/output_graph.pbmm\n",
      "Loaded model in 0.0216s.\n",
      "Loading language model from files ../models/deepspeech/deepspeech-0.6.0-models/lm.binary ../models/deepspeech/deepspeech-0.6.0-models/trie\n",
      "Loaded language model in 0.000535s.\n",
      "Warning: original sample rate (48000) is different than 16000hz. Resampling might produce erratic speech recognition.\n",
      "Running inference.\n",
      "Inference took 5.664s for 37.376s audio file.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing  in the night the music as personalities pepe she cardinalates star to my play music\n",
      "keyword detected\n",
      "playing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading model from file ../models/deepspeech/deepspeech-0.6.0-models/output_graph.pbmm\n",
      "Loaded model in 0.0196s.\n",
      "Loading language model from files ../models/deepspeech/deepspeech-0.6.0-models/lm.binary ../models/deepspeech/deepspeech-0.6.0-models/trie\n",
      "Loaded language model in 0.000354s.\n",
      "Warning: original sample rate (48000) is different than 16000hz. Resampling might produce erratic speech recognition.\n",
      "Running inference.\n",
      "Inference took 6.839s for 46.592s audio file.\n",
      "Loading model from file ../models/deepspeech/deepspeech-0.6.0-models/output_graph.pbmm\n",
      "Loaded model in 0.00436s.\n",
      "Loading language model from files ../models/deepspeech/deepspeech-0.6.0-models/lm.binary ../models/deepspeech/deepspeech-0.6.0-models/trie\n",
      "Loaded language model in 0.000187s.\n",
      "Warning: original sample rate (48000) is different than 16000hz. Resampling might produce erratic speech recognition.\n",
      "Running inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing  how are you to get a liberal goddess my flame you see or my pinions\n",
      "keyword detected\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference took 1.136s for 7.424s audio file.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing  i\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading model from file ../models/deepspeech/deepspeech-0.6.0-models/output_graph.pbmm\n",
      "Loaded model in 0.0217s.\n",
      "Loading language model from files ../models/deepspeech/deepspeech-0.6.0-models/lm.binary ../models/deepspeech/deepspeech-0.6.0-models/trie\n",
      "Loaded language model in 0.000578s.\n",
      "Warning: original sample rate (48000) is different than 16000hz. Resampling might produce erratic speech recognition.\n",
      "Running inference.\n",
      "Inference took 0.964s for 5.632s audio file.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing  i\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading model from file ../models/deepspeech/deepspeech-0.6.0-models/output_graph.pbmm\n",
      "Loaded model in 0.0221s.\n",
      "Loading language model from files ../models/deepspeech/deepspeech-0.6.0-models/lm.binary ../models/deepspeech/deepspeech-0.6.0-models/trie\n",
      "Loaded language model in 0.000383s.\n",
      "Warning: original sample rate (48000) is different than 16000hz. Resampling might produce erratic speech recognition.\n",
      "Running inference.\n",
      "Inference took 6.947s for 46.080s audio file.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing  my blame your sick might blame you seek my pain music there was a glare as in tetuan to atone by the giver\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading model from file ../models/deepspeech/deepspeech-0.6.0-models/output_graph.pbmm\n",
      "Loaded model in 0.0182s.\n",
      "Loading language model from files ../models/deepspeech/deepspeech-0.6.0-models/lm.binary ../models/deepspeech/deepspeech-0.6.0-models/trie\n",
      "Loaded language model in 0.000935s.\n",
      "Warning: original sample rate (48000) is different than 16000hz. Resampling might produce erratic speech recognition.\n",
      "Running inference.\n",
      "Inference took 5.861s for 39.424s audio file.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing  he mainwaring all is this go to save the moselle a basin is\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading model from file ../models/deepspeech/deepspeech-0.6.0-models/output_graph.pbmm\n",
      "Loaded model in 0.019s.\n",
      "Loading language model from files ../models/deepspeech/deepspeech-0.6.0-models/lm.binary ../models/deepspeech/deepspeech-0.6.0-models/trie\n",
      "Loaded language model in 0.000782s.\n",
      "Warning: original sample rate (48000) is different than 16000hz. Resampling might produce erratic speech recognition.\n",
      "Running inference.\n",
      "Inference took 6.947s for 45.568s audio file.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing  and then you should mooseheart tis the same barony as agencies is a boon said my play me\n",
      "keyword detected\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading model from file ../models/deepspeech/deepspeech-0.6.0-models/output_graph.pbmm\n",
      "Loaded model in 0.0204s.\n",
      "Loading language model from files ../models/deepspeech/deepspeech-0.6.0-models/lm.binary ../models/deepspeech/deepspeech-0.6.0-models/trie\n",
      "Loaded language model in 0.00086s.\n",
      "Warning: original sample rate (48000) is different than 16000hz. Resampling might produce erratic speech recognition.\n",
      "Running inference.\n",
      "Inference took 6.821s for 45.312s audio file.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing  my play will want a potation my him play music basing hesitation new napata mile clay nursed my ole\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading model from file ../models/deepspeech/deepspeech-0.6.0-models/output_graph.pbmm\n",
      "Loaded model in 0.0184s.\n",
      "Loading language model from files ../models/deepspeech/deepspeech-0.6.0-models/lm.binary ../models/deepspeech/deepspeech-0.6.0-models/trie\n",
      "Loaded language model in 0.000955s.\n",
      "Warning: original sample rate (48000) is different than 16000hz. Resampling might produce erratic speech recognition.\n",
      "Running inference.\n",
      "Inference took 6.679s for 45.312s audio file.\n",
      "Loading model from file ../models/deepspeech/deepspeech-0.6.0-models/output_graph.pbmm\n",
      "Loaded model in 0.00438s.\n",
      "Loading language model from files ../models/deepspeech/deepspeech-0.6.0-models/lm.binary ../models/deepspeech/deepspeech-0.6.0-models/trie\n",
      "Loaded language model in 0.000189s.\n",
      "Warning: original sample rate (48000) is different than 16000hz. Resampling might produce erratic speech recognition.\n",
      "Running inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing  that is a annorah my blade music my play near sick my plague music\n",
      "keyword detected\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference took 2.086s for 14.080s audio file.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing  he\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading model from file ../models/deepspeech/deepspeech-0.6.0-models/output_graph.pbmm\n",
      "Loaded model in 0.0208s.\n",
      "Loading language model from files ../models/deepspeech/deepspeech-0.6.0-models/lm.binary ../models/deepspeech/deepspeech-0.6.0-models/trie\n",
      "Loaded language model in 0.000806s.\n",
      "Warning: original sample rate (48000) is different than 16000hz. Resampling might produce erratic speech recognition.\n",
      "Running inference.\n",
      "Inference took 3.229s for 21.248s audio file.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing  a\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading model from file ../models/deepspeech/deepspeech-0.6.0-models/output_graph.pbmm\n",
      "Loaded model in 0.0184s.\n",
      "Loading language model from files ../models/deepspeech/deepspeech-0.6.0-models/lm.binary ../models/deepspeech/deepspeech-0.6.0-models/trie\n",
      "Loaded language model in 0.000713s.\n",
      "Warning: original sample rate (48000) is different than 16000hz. Resampling might produce erratic speech recognition.\n",
      "Running inference.\n",
      "Inference took 6.912s for 46.336s audio file.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing  and the oregon u with a eolists my play music my play music my play miss ah \n",
      "keyword detected\n",
      "playing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading model from file ../models/deepspeech/deepspeech-0.6.0-models/output_graph.pbmm\n",
      "Loaded model in 0.0185s.\n",
      "Loading language model from files ../models/deepspeech/deepspeech-0.6.0-models/lm.binary ../models/deepspeech/deepspeech-0.6.0-models/trie\n",
      "Loaded language model in 0.000412s.\n",
      "Warning: original sample rate (48000) is different than 16000hz. Resampling might produce erratic speech recognition.\n",
      "Running inference.\n",
      "Inference took 6.763s for 45.312s audio file.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing  i am charmian that love and law you know he will be an began\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading model from file ../models/deepspeech/deepspeech-0.6.0-models/output_graph.pbmm\n",
      "Loaded model in 0.018s.\n",
      "Loading language model from files ../models/deepspeech/deepspeech-0.6.0-models/lm.binary ../models/deepspeech/deepspeech-0.6.0-models/trie\n",
      "Loaded language model in 0.000798s.\n",
      "Warning: original sample rate (48000) is different than 16000hz. Resampling might produce erratic speech recognition.\n",
      "Running inference.\n",
      "Inference took 6.627s for 45.312s audio file.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing  the caiarara then idea in magyar beneath\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading model from file ../models/deepspeech/deepspeech-0.6.0-models/output_graph.pbmm\n",
      "Loaded model in 0.00681s.\n",
      "Loading language model from files ../models/deepspeech/deepspeech-0.6.0-models/lm.binary ../models/deepspeech/deepspeech-0.6.0-models/trie\n",
      "Loaded language model in 0.000271s.\n",
      "Warning: original sample rate (48000) is different than 16000hz. Resampling might produce erratic speech recognition.\n",
      "Running inference.\n",
      "Inference took 6.850s for 45.312s audio file.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing  the vagaries and attention of all other elmwood is as missaid me miss putting in daleshire with romaine to bid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading model from file ../models/deepspeech/deepspeech-0.6.0-models/output_graph.pbmm\n",
      "Loaded model in 0.0186s.\n",
      "Loading language model from files ../models/deepspeech/deepspeech-0.6.0-models/lm.binary ../models/deepspeech/deepspeech-0.6.0-models/trie\n",
      "Loaded language model in 0.000597s.\n",
      "Warning: original sample rate (48000) is different than 16000hz. Resampling might produce erratic speech recognition.\n",
      "Running inference.\n",
      "Inference took 6.703s for 45.312s audio file.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing  that is the lesson but as she is my hotel and i went she missed\n",
      "keyword detected\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading model from file ../models/deepspeech/deepspeech-0.6.0-models/output_graph.pbmm\n",
      "Loaded model in 0.0239s.\n",
      "Loading language model from files ../models/deepspeech/deepspeech-0.6.0-models/lm.binary ../models/deepspeech/deepspeech-0.6.0-models/trie\n",
      "Loaded language model in 0.000811s.\n",
      "Warning: original sample rate (48000) is different than 16000hz. Resampling might produce erratic speech recognition.\n",
      "Running inference.\n",
      "Inference took 6.682s for 45.312s audio file.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing  so anaesthesia the batteries and must not let slip an nobilitee \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading model from file ../models/deepspeech/deepspeech-0.6.0-models/output_graph.pbmm\n",
      "Loaded model in 0.0189s.\n",
      "Loading language model from files ../models/deepspeech/deepspeech-0.6.0-models/lm.binary ../models/deepspeech/deepspeech-0.6.0-models/trie\n",
      "Loaded language model in 0.000742s.\n",
      "Warning: original sample rate (48000) is different than 16000hz. Resampling might produce erratic speech recognition.\n",
      "Running inference.\n",
      "Inference took 6.960s for 45.312s audio file.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing  as a owas it am me in bellaggio aboard ariela as the wind that came tepelenti become in consultation to offer myself as a\n",
      "keyword detected\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading model from file ../models/deepspeech/deepspeech-0.6.0-models/output_graph.pbmm\n",
      "Loaded model in 0.0187s.\n",
      "Loading language model from files ../models/deepspeech/deepspeech-0.6.0-models/lm.binary ../models/deepspeech/deepspeech-0.6.0-models/trie\n",
      "Loaded language model in 0.000788s.\n",
      "Warning: original sample rate (48000) is different than 16000hz. Resampling might produce erratic speech recognition.\n",
      "Running inference.\n",
      "Inference took 6.835s for 45.312s audio file.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing  go bealeton business gobernacion sibeilka have a war they were her\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading model from file ../models/deepspeech/deepspeech-0.6.0-models/output_graph.pbmm\n",
      "Loaded model in 0.023s.\n",
      "Loading language model from files ../models/deepspeech/deepspeech-0.6.0-models/lm.binary ../models/deepspeech/deepspeech-0.6.0-models/trie\n",
      "Loaded language model in 0.000635s.\n",
      "Warning: original sample rate (48000) is different than 16000hz. Resampling might produce erratic speech recognition.\n",
      "Running inference.\n",
      "Inference took 6.965s for 45.312s audio file.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing  oh i heard of the institute with a wolf having her not to move then you can use my mind as meseemeth\n",
      "keyword detected\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading model from file ../models/deepspeech/deepspeech-0.6.0-models/output_graph.pbmm\n",
      "Loaded model in 0.0188s.\n",
      "Loading language model from files ../models/deepspeech/deepspeech-0.6.0-models/lm.binary ../models/deepspeech/deepspeech-0.6.0-models/trie\n",
      "Loaded language model in 0.00106s.\n",
      "Warning: original sample rate (48000) is different than 16000hz. Resampling might produce erratic speech recognition.\n",
      "Running inference.\n",
      "Inference took 6.669s for 45.312s audio file.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing  one i got in a means to an aedile\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading model from file ../models/deepspeech/deepspeech-0.6.0-models/output_graph.pbmm\n",
      "Loaded model in 0.00796s.\n",
      "Loading language model from files ../models/deepspeech/deepspeech-0.6.0-models/lm.binary ../models/deepspeech/deepspeech-0.6.0-models/trie\n",
      "Loaded language model in 0.000443s.\n",
      "Warning: original sample rate (48000) is different than 16000hz. Resampling might produce erratic speech recognition.\n",
      "Running inference.\n",
      "Inference took 6.892s for 45.312s audio file.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing  no but it doesn't earn thieving but you what brought up was garconnet were most commanders to asiatic areas completer state\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading model from file ../models/deepspeech/deepspeech-0.6.0-models/output_graph.pbmm\n",
      "Loaded model in 0.01s.\n",
      "Loading language model from files ../models/deepspeech/deepspeech-0.6.0-models/lm.binary ../models/deepspeech/deepspeech-0.6.0-models/trie\n",
      "Loaded language model in 0.000285s.\n",
      "Warning: original sample rate (48000) is different than 16000hz. Resampling might produce erratic speech recognition.\n",
      "Running inference.\n",
      "Inference took 6.982s for 45.312s audio file.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing  in the night he lamentation the young one of the engagement what are tonsilectomy fiscal establish my easement in easing when the critics\n",
      "keyword detected\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading model from file ../models/deepspeech/deepspeech-0.6.0-models/output_graph.pbmm\n",
      "Loaded model in 0.0187s.\n",
      "Loading language model from files ../models/deepspeech/deepspeech-0.6.0-models/lm.binary ../models/deepspeech/deepspeech-0.6.0-models/trie\n",
      "Loaded language model in 0.000942s.\n",
      "Warning: original sample rate (48000) is different than 16000hz. Resampling might produce erratic speech recognition.\n",
      "Running inference.\n",
      "Inference took 6.847s for 45.312s audio file.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing  necessities of aeternitatis is an besides he knew it yes sipehsalar made was\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading model from file ../models/deepspeech/deepspeech-0.6.0-models/output_graph.pbmm\n",
      "Loaded model in 0.0132s.\n",
      "Loading language model from files ../models/deepspeech/deepspeech-0.6.0-models/lm.binary ../models/deepspeech/deepspeech-0.6.0-models/trie\n",
      "Loaded language model in 0.000229s.\n",
      "Warning: original sample rate (48000) is different than 16000hz. Resampling might produce erratic speech recognition.\n",
      "Running inference.\n",
      "Inference took 6.926s for 45.568s audio file.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing  and beneath it a safe at the meals beside us a lad so to get\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading model from file ../models/deepspeech/deepspeech-0.6.0-models/output_graph.pbmm\n",
      "Loaded model in 0.00902s.\n",
      "Loading language model from files ../models/deepspeech/deepspeech-0.6.0-models/lm.binary ../models/deepspeech/deepspeech-0.6.0-models/trie\n",
      "Loaded language model in 0.000454s.\n",
      "Warning: original sample rate (48000) is different than 16000hz. Resampling might produce erratic speech recognition.\n",
      "Running inference.\n",
      "Inference took 7.461s for 45.568s audio file.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing  it bite after the israelite who not a sin you pull gisele etiolated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading model from file ../models/deepspeech/deepspeech-0.6.0-models/output_graph.pbmm\n",
      "Loaded model in 0.00748s.\n",
      "Loading language model from files ../models/deepspeech/deepspeech-0.6.0-models/lm.binary ../models/deepspeech/deepspeech-0.6.0-models/trie\n",
      "Loaded language model in 0.00055s.\n",
      "Warning: original sample rate (48000) is different than 16000hz. Resampling might produce erratic speech recognition.\n",
      "Running inference.\n",
      "Inference took 6.950s for 45.824s audio file.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing  to the mormon idea but i petition with a live politeness some of the delicate\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading model from file ../models/deepspeech/deepspeech-0.6.0-models/output_graph.pbmm\n",
      "Loaded model in 0.0186s.\n",
      "Loading language model from files ../models/deepspeech/deepspeech-0.6.0-models/lm.binary ../models/deepspeech/deepspeech-0.6.0-models/trie\n",
      "Loaded language model in 0.000807s.\n",
      "Warning: original sample rate (48000) is different than 16000hz. Resampling might produce erratic speech recognition.\n",
      "Running inference.\n",
      "Inference took 6.756s for 45.312s audio file.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing  the engleman organ arena batabano \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading model from file ../models/deepspeech/deepspeech-0.6.0-models/output_graph.pbmm\n",
      "Loaded model in 0.00702s.\n",
      "Loading language model from files ../models/deepspeech/deepspeech-0.6.0-models/lm.binary ../models/deepspeech/deepspeech-0.6.0-models/trie\n",
      "Loaded language model in 0.000367s.\n",
      "Warning: original sample rate (48000) is different than 16000hz. Resampling might produce erratic speech recognition.\n",
      "Running inference.\n",
      "Inference took 8.119s for 45.312s audio file.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing  let no told said that the stone lifting up \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading model from file ../models/deepspeech/deepspeech-0.6.0-models/output_graph.pbmm\n",
      "Loaded model in 0.0189s.\n",
      "Loading language model from files ../models/deepspeech/deepspeech-0.6.0-models/lm.binary ../models/deepspeech/deepspeech-0.6.0-models/trie\n",
      "Loaded language model in 0.00077s.\n",
      "Warning: original sample rate (48000) is different than 16000hz. Resampling might produce erratic speech recognition.\n",
      "Running inference.\n",
      "Inference took 9.064s for 45.824s audio file.\n",
      "Loading model from file ../models/deepspeech/deepspeech-0.6.0-models/output_graph.pbmm\n",
      "Loaded model in 0.00765s.\n",
      "Loading language model from files ../models/deepspeech/deepspeech-0.6.0-models/lm.binary ../models/deepspeech/deepspeech-0.6.0-models/trie\n",
      "Loaded language model in 0.000423s.\n",
      "Warning: original sample rate (48000) is different than 16000hz. Resampling might produce erratic speech recognition.\n",
      "Running inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing  he\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference took 1.829s for 8.192s audio file.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing  oh \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading model from file ../models/deepspeech/deepspeech-0.6.0-models/output_graph.pbmm\n",
      "Loaded model in 0.00698s.\n",
      "Loading language model from files ../models/deepspeech/deepspeech-0.6.0-models/lm.binary ../models/deepspeech/deepspeech-0.6.0-models/trie\n",
      "Loaded language model in 0.000476s.\n",
      "Warning: original sample rate (48000) is different than 16000hz. Resampling might produce erratic speech recognition.\n",
      "Running inference.\n",
      "Inference took 2.813s for 13.312s audio file.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing  i\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading model from file ../models/deepspeech/deepspeech-0.6.0-models/output_graph.pbmm\n",
      "Loaded model in 0.0252s.\n",
      "Loading language model from files ../models/deepspeech/deepspeech-0.6.0-models/lm.binary ../models/deepspeech/deepspeech-0.6.0-models/trie\n",
      "Loaded language model in 0.000807s.\n",
      "Warning: original sample rate (48000) is different than 16000hz. Resampling might produce erratic speech recognition.\n",
      "Running inference.\n",
      "Inference took 4.117s for 18.944s audio file.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing  no\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading model from file ../models/deepspeech/deepspeech-0.6.0-models/output_graph.pbmm\n",
      "Loaded model in 0.0196s.\n",
      "Loading language model from files ../models/deepspeech/deepspeech-0.6.0-models/lm.binary ../models/deepspeech/deepspeech-0.6.0-models/trie\n",
      "Loaded language model in 0.000861s.\n",
      "Warning: original sample rate (48000) is different than 16000hz. Resampling might produce erratic speech recognition.\n",
      "Running inference.\n",
      "Inference took 6.734s for 31.744s audio file.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing  oh\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading model from file ../models/deepspeech/deepspeech-0.6.0-models/output_graph.pbmm\n",
      "Loaded model in 0.00758s.\n",
      "Loading language model from files ../models/deepspeech/deepspeech-0.6.0-models/lm.binary ../models/deepspeech/deepspeech-0.6.0-models/trie\n",
      "Loaded language model in 0.000354s.\n",
      "Warning: original sample rate (48000) is different than 16000hz. Resampling might produce erratic speech recognition.\n",
      "Running inference.\n",
      "Inference took 7.969s for 46.336s audio file.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing  i\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading model from file ../models/deepspeech/deepspeech-0.6.0-models/output_graph.pbmm\n",
      "Loaded model in 0.0167s.\n",
      "Loading language model from files ../models/deepspeech/deepspeech-0.6.0-models/lm.binary ../models/deepspeech/deepspeech-0.6.0-models/trie\n",
      "Loaded language model in 0.000446s.\n",
      "Warning: original sample rate (48000) is different than 16000hz. Resampling might produce erratic speech recognition.\n",
      "Running inference.\n",
      "Inference took 9.369s for 45.312s audio file.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing  hello my friend that you\n",
      "keyword detected\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading model from file ../models/deepspeech/deepspeech-0.6.0-models/output_graph.pbmm\n",
      "Loaded model in 0.0124s.\n",
      "Loading language model from files ../models/deepspeech/deepspeech-0.6.0-models/lm.binary ../models/deepspeech/deepspeech-0.6.0-models/trie\n",
      "Loaded language model in 0.000662s.\n",
      "Warning: original sample rate (48000) is different than 16000hz. Resampling might produce erratic speech recognition.\n",
      "Running inference.\n",
      "Inference took 11.885s for 46.592s audio file.\n",
      "Loading model from file ../models/deepspeech/deepspeech-0.6.0-models/output_graph.pbmm\n",
      "Loaded model in 0.00858s.\n",
      "Loading language model from files ../models/deepspeech/deepspeech-0.6.0-models/lm.binary ../models/deepspeech/deepspeech-0.6.0-models/trie\n",
      "Loaded language model in 0.000387s.\n",
      "Warning: original sample rate (48000) is different than 16000hz. Resampling might produce erratic speech recognition.\n",
      "Running inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing  the wind\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference took 0.991s for 4.352s audio file.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing  i\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading model from file ../models/deepspeech/deepspeech-0.6.0-models/output_graph.pbmm\n",
      "Loaded model in 0.0233s.\n",
      "Loading language model from files ../models/deepspeech/deepspeech-0.6.0-models/lm.binary ../models/deepspeech/deepspeech-0.6.0-models/trie\n",
      "Loaded language model in 0.000802s.\n",
      "Warning: original sample rate (48000) is different than 16000hz. Resampling might produce erratic speech recognition.\n",
      "Running inference.\n",
      "Inference took 2.383s for 10.240s audio file.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing  i\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading model from file ../models/deepspeech/deepspeech-0.6.0-models/output_graph.pbmm\n",
      "Loaded model in 0.023s.\n",
      "Loading language model from files ../models/deepspeech/deepspeech-0.6.0-models/lm.binary ../models/deepspeech/deepspeech-0.6.0-models/trie\n",
      "Loaded language model in 0.000561s.\n",
      "Warning: original sample rate (48000) is different than 16000hz. Resampling might produce erratic speech recognition.\n",
      "Running inference.\n",
      "Inference took 3.934s for 18.944s audio file.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing  a\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading model from file ../models/deepspeech/deepspeech-0.6.0-models/output_graph.pbmm\n",
      "Loaded model in 0.0198s.\n",
      "Loading language model from files ../models/deepspeech/deepspeech-0.6.0-models/lm.binary ../models/deepspeech/deepspeech-0.6.0-models/trie\n",
      "Loaded language model in 0.000813s.\n",
      "Warning: original sample rate (48000) is different than 16000hz. Resampling might produce erratic speech recognition.\n",
      "Running inference.\n",
      "Inference took 9.172s for 45.824s audio file.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing  i\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading model from file ../models/deepspeech/deepspeech-0.6.0-models/output_graph.pbmm\n",
      "Loaded model in 0.0189s.\n",
      "Loading language model from files ../models/deepspeech/deepspeech-0.6.0-models/lm.binary ../models/deepspeech/deepspeech-0.6.0-models/trie\n",
      "Loaded language model in 0.000972s.\n",
      "Warning: original sample rate (48000) is different than 16000hz. Resampling might produce erratic speech recognition.\n",
      "Running inference.\n",
      "Inference took 1.376s for 5.888s audio file.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing  i\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading model from file ../models/deepspeech/deepspeech-0.6.0-models/output_graph.pbmm\n",
      "Loaded model in 0.0202s.\n",
      "Loading language model from files ../models/deepspeech/deepspeech-0.6.0-models/lm.binary ../models/deepspeech/deepspeech-0.6.0-models/trie\n",
      "Loaded language model in 0.000836s.\n",
      "Warning: original sample rate (48000) is different than 16000hz. Resampling might produce erratic speech recognition.\n",
      "Running inference.\n",
      "Inference took 1.773s for 6.912s audio file.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing  i\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading model from file ../models/deepspeech/deepspeech-0.6.0-models/output_graph.pbmm\n",
      "Loaded model in 0.0231s.\n",
      "Loading language model from files ../models/deepspeech/deepspeech-0.6.0-models/lm.binary ../models/deepspeech/deepspeech-0.6.0-models/trie\n",
      "Loaded language model in 0.000801s.\n",
      "Warning: original sample rate (48000) is different than 16000hz. Resampling might produce erratic speech recognition.\n",
      "Running inference.\n",
      "Inference took 1.430s for 5.632s audio file.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing  i\n"
     ]
    }
   ],
   "source": [
    "meeting_facilitator.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading model from file ../models/deepspeech/deepspeech-0.6.0-models/output_graph.pbmm\n",
      "Loaded model in 0.0236s.\n",
      "Loading language model from files ../models/deepspeech/deepspeech-0.6.0-models/lm.binary ../models/deepspeech/deepspeech-0.6.0-models/trie\n",
      "Loaded language model in 0.000997s.\n",
      "Warning: original sample rate (48000) is different than 16000hz. Resampling might produce erratic speech recognition.\n",
      "Running inference.\n",
      "Inference took 5.952s for 39.424s audio file.\n"
     ]
    }
   ],
   "source": [
    "meeting_facilitator.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<MeetingFacilitator>\tobject has children:\n",
      "    <str>\tmeeting_name:\tmy_meeting\n",
      "    <str>\tdate:\t2020-01-02 18:31:20.873474\n",
      "    <NoneType>\tattendants:\tNone\n",
      "    <str>\taudios_folder:\t../meetings/my_meeting/audios/\n",
      "    <str>\treports_folder:\t..meetings/my_meeting/reports/\n",
      "    <Transcriber>\ttranscriber\n",
      "    <SpeechCommandsHandler>\tspeech_command_handler\n",
      "    <SpeechCommandsHandler>\tspeech_command_handler\n",
      "    <bool>\t_is_handling_commands:\tFalse\n",
      "    <list>\t_trainscriptions_list\n",
      "    <EmailConfig>\temail_config\n",
      "\n",
      "  <EmailConfig>\temail_config has children:\n",
      "\n",
      "  <list>\t_trainscriptions_list has children:\n",
      "\n",
      "  <SpeechCommandsHandler>\tspeech_command_handler has children:\n",
      "\n",
      "  <SpeechCommandsHandler>\tspeech_command_handler has children:\n",
      "\n",
      "  <Transcriber>\ttranscriber has children:\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "unwrap(meeting_facilitator, max_level = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Meeting Facilitator Control panel\n",
    "\n",
    "Small UI to visualize how the process is doing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
